{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as numpy\n",
    "import os\n",
    "import logging\n",
    "\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:/Custom Training/train'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "IMG_HEIGHT = 180\n",
    "IMG_WIDTH = 180\n",
    "\n",
    "\n",
    "# Define variables\n",
    "NUM_CLASSES = 2\n",
    "EPOCHS=10\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "DATA_DIR = \"D:/Custom Training/train\"\n",
    "DATA_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_img(image):\n",
    "    \n",
    "    image = tf.image.resize_with_pad(image, IMG_WIDTH, IMG_WIDTH)\n",
    "    return image / 255.\n",
    "\n",
    "def normalize_img_and_label(image, label):    \n",
    "    return normalize_img(image), label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_image(filename):\n",
    "    parts = tf.strings.split(filename, os.path.sep)\n",
    "    label = parts[-2]  # Extract label from the second-to-last part of the path\n",
    "    one_hot_label = tf.one_hot(tf.cast(label == 'dogs', tf.int32), NUM_CLASSES)\n",
    "    image = tf.io.read_file(filename)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    \n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    return image, one_hot_label\n",
    "\n",
    "# Define dataset path\n",
    "DATA_DIR = \"./train\"\n",
    "\n",
    "# List files recursively from the dataset directory\n",
    "file_list = tf.data.Dataset.list_files(DATA_DIR + '/cats/*.jpg') \\\n",
    "            .concatenate(tf.data.Dataset.list_files(DATA_DIR + '/dogs/*.jpg'))\n",
    "\n",
    "# Map parsing function to the dataset\n",
    "dataset = file_list.map(parse_image)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "output_directory = \"./output\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "456/456 [==============================] - 41s 86ms/step - loss: 27.0065 - accuracy: 0.9912\n",
      "Epoch 2/10\n",
      "456/456 [==============================] - 34s 75ms/step - loss: 25.5213 - accuracy: 0.9781\n",
      "Epoch 3/10\n",
      "456/456 [==============================] - 33s 72ms/step - loss: 1.7341 - accuracy: 0.9693\n",
      "Epoch 4/10\n",
      "456/456 [==============================] - 32s 70ms/step - loss: 0.4533 - accuracy: 0.9156\n",
      "Epoch 5/10\n",
      "456/456 [==============================] - 34s 74ms/step - loss: 0.4758 - accuracy: 0.9079\n",
      "Epoch 6/10\n",
      "456/456 [==============================] - 36s 79ms/step - loss: 0.3632 - accuracy: 0.9068\n",
      "Epoch 7/10\n",
      "456/456 [==============================] - 116s 254ms/step - loss: 0.5090 - accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "456/456 [==============================] - 34s 75ms/step - loss: 3.9738 - accuracy: 0.8860\n",
      "Epoch 9/10\n",
      "456/456 [==============================] - 33s 73ms/step - loss: 0.6033 - accuracy: 0.9287\n",
      "Epoch 10/10\n",
      "456/456 [==============================] - 33s 72ms/step - loss: 0.5356 - accuracy: 0.8969\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./output\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./output\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "logging.info('Creating and training model ...')\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(16,\n",
    "                           3,\n",
    "                           padding='same',\n",
    "                           activation='relu',\n",
    "                           input_shape=(IMG_WIDTH, IMG_WIDTH, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')  \n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "model.fit(dataset, epochs=10)\n",
    "\n",
    "logging.info(f'Exporting SavedModel to: {output_directory}')\n",
    "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "probability_model.save(output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the saved model\n",
    "model = tf.saved_model.load('./output/')\n",
    "\n",
    "# Prepare the input data\n",
    "img_path = './23.jpg'\n",
    "\n",
    "img = tf.io.read_file(img_path)\n",
    "img = tf.image.decode_image(img, channels=3)\n",
    "img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
    "img = img / 255.0\n",
    "img = tf.expand_dims(img, axis=0)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model(img)\n",
    "\n",
    "# Process the predictions\n",
    "predicted_class = tf.argmax(predictions, axis=1).numpy()[0]\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
